{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying MNIST with a simple model and quantum embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by:  https://www.kaggle.com/code/geekysaint/solving-mnist-using-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the Boson Sampler\n",
    "import perceval as pcvl\n",
    "#import perceval.providers.scaleway as scw  # Uncomment to allow running on scaleway\n",
    "\n",
    "# for the machine learning model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from boson_sampler import BosonSampler\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "from model128 import *\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Boson Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 85, and embedding size = 45\n",
      "DEVICE = cpu\n"
     ]
    }
   ],
   "source": [
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "# definition of the BosonSampler\n",
    "# here, we use 30 photons and 2 modes\n",
    "\n",
    "bs = BosonSampler(10,2, postselect = 2, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs.nb_parameters}, and embedding size = {bs.embedding_size}\")\n",
    "\n",
    "#to display it\n",
    "# pcvl.pdisplay(bs.create_circuit())\n",
    "# define device to run the model\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset : a subset of MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([10, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, batch, emb = None):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    images.requires_grad = True  # Only needed for special cases\n",
    "    # if self.embedding_size:\n",
    "    #     out = self(images, emb.to(self.device)) ## Generate predictions\n",
    "    # else:\n",
    "    # images = images.reshape(-1,1,28,28)\n",
    "    # print(images.shape)\n",
    "\n",
    "    # out = model(images) ## Generate predictions\n",
    "    # loss = F.cross_entropy(out, labels)\n",
    "    # acc = accuracy(out, labels, task=\"multiclass\", num_classes=10)\n",
    "    loss, acc = model((images, labels)) ## Generate predictions\n",
    "    \n",
    "    # loss = F.cross_entropy(out, labels) ## Calculate the loss\n",
    "    # acc = accuracy(out, labels)\n",
    "    return loss, acc\n",
    "\n",
    "def validation_step(model, batch, emb =None):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    images.requires_grad = True  # Only needed for special cases\n",
    "    # if self.embedding_size:\n",
    "    #     out = self(images, emb.to(self.device)) ## Generate predictions\n",
    "    # # else:\n",
    "    # out = model(images) ## Generate predictions\n",
    "    # loss = F.cross_entropy(out, labels)\n",
    "    # acc = accuracy(out, labels, task=\"multiclass\", num_classes=10)\n",
    "    loss, acc = model((images,labels)) ## Generate predictions\n",
    "    return({'val_loss':loss, 'val_acc': acc})\n",
    "\n",
    "def validation_epoch_end(outputs):\n",
    "    batch_losses = [x['val_loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean()\n",
    "    batch_accs = [x['val_acc'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()\n",
    "    return({'val_loss': epoch_loss.item(), 'val_acc' : epoch_acc.item()})\n",
    "\n",
    "def epoch_end(epoch, result):\n",
    "    print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "    return result['val_loss'], result['val_acc']\n",
    "\n",
    "# training loop\n",
    "def fit(epochs, lr, model, train_loader, val_loader, bs: BosonSampler, opt_func = torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func([{'params': model.model.fc.parameters(), 'lr': lr},{'params': model.model.conv1.parameters(), 'lr': lr}])\n",
    "    # creation of empty lists to store the training metrics\n",
    "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        training_losses, training_accs = 0, 0\n",
    "        ## Training Phase\n",
    "        for step, batch in enumerate(tqdm(train_loader)):\n",
    "            # # embedding in the BS\n",
    "            # if model.embedding_size:\n",
    "            #     images, labs = batch\n",
    "            #     images = images.squeeze(0).squeeze(0)\n",
    "            #     t_s = time.time()\n",
    "            #     embs = bs.embed(images,1000)\n",
    "            #     loss,acc = model.training_step(batch,emb = embs.unsqueeze(0))\n",
    "\n",
    "            # else:\n",
    "            \n",
    "            loss,acc = training_step(model, batch)\n",
    "            # loss.requires_grad = True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backpropagation with boson sampling noise\n",
    "            # for param in model.parameters():\n",
    "            #     param.grad = param.grad + bs(param.grad.shape, scale=0.001)\n",
    "\n",
    "            training_losses+=int(loss.detach())\n",
    "            training_accs+=int(acc.detach())\n",
    "            # if model.embedding_size and step%100==0:\n",
    "            #     print(f\"STEP {step}, Training-acc = {training_accs/(step+1)}, Training-losses = {training_losses/(step+1)}\")\n",
    "        \n",
    "        ## Validation phase\n",
    "        outputs = [validation_step(model, batch) for batch in val_loader]\n",
    "        result = (validation_epoch_end(outputs))\n",
    "        # result = evaluate(model, val_loader, bs)\n",
    "        validation_loss, validation_acc = result['val_loss'], result['val_acc']\n",
    "        epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "        ## summing up all the training and validation metrics\n",
    "        training_loss = training_losses/len(train_loader)\n",
    "        training_accs = training_accs/len(train_loader)\n",
    "        train_loss.append(training_loss)\n",
    "        train_acc.append(training_accs)\n",
    "        val_loss.append(validation_loss)\n",
    "        val_acc.append(validation_acc)\n",
    "\n",
    "        # plot training curves\n",
    "        \n",
    "\n",
    "    with open('tmp_file.txt', 'w') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows([train_acc,val_acc,train_loss,val_loss])\n",
    "        # plot_training_metrics(train_acc,val_acc,train_loss,val_loss)\n",
    "    return(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check original accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pre_trained import *\n",
    "# trainer = Trainer(\n",
    "#     fast_dev_run=False,\n",
    "#     # logger=TensorBoardLogger(\"cifar10\", name='resnet18'),\n",
    "#     deterministic=True,\n",
    "#     log_every_n_steps=1,\n",
    "#     max_epochs=100,\n",
    "#     precision=32,\n",
    "# )\n",
    "\n",
    "# model = CIFAR10Module(minst=True)\n",
    "# model.load_state_dict(torch.load('state_dicts/resnet18.pt'), strict=False)\n",
    "# trainer.test(model, val_loader)\n",
    "\n",
    "# [{'acc/test': 10.833333015441895}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CIFAR10Module(minst=False)\n",
    "# data = CIFAR10Data()\n",
    "# model.model.load_state_dict(torch.load('state_dicts/resnet18.pt'))\n",
    "# trainer.test(model, data.val_dataloader())\n",
    "\n",
    "# [{'acc/test': 93.06890869140625}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CIFAR10Module(minst=True)\n",
    "# # data = CIFAR10Data()\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# # Unfreeze the last layer\n",
    "# for param in model.model.conv1.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.model.fc.parameters():\n",
    "#     param.requires_grad = True\n",
    "# pretrained_dict = torch.load(\"state_dicts/resnet18.pt\")  # Path to saved weights\n",
    "# model_dict = model.state_dict()\n",
    "\n",
    "# # Remove 'conv1' weights from pretrained_dict to avoid shape mismatch\n",
    "# pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"conv1\" or 'fc' not in k}\n",
    "\n",
    "# # Update the current model dictionary\n",
    "# model_dict.update(pretrained_dict)\n",
    "\n",
    "# # Load the modified weights\n",
    "# model.load_state_dict(model_dict, strict=False) \n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = fit(epochs = 20, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)\n",
    "\n",
    "# 100%|██████████| 600/600 [00:28<00:00, 20.78it/s]\n",
    "# Epoch [0], val_loss: 1.3817, val_acc: 62.0000\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 26.77it/s]\n",
    "# Epoch [1], val_loss: 1.0354, val_acc: 69.3333\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 26.83it/s]\n",
    "# Epoch [2], val_loss: 0.8341, val_acc: 77.1667\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 26.98it/s]\n",
    "# Epoch [3], val_loss: 0.7472, val_acc: 77.5000\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 27.38it/s]\n",
    "# Epoch [4], val_loss: 0.6718, val_acc: 80.1667\n",
    "# 100%|██████████| 600/600 [00:20<00:00, 29.88it/s]\n",
    "# Epoch [5], val_loss: 0.6378, val_acc: 81.1667\n",
    "# 100%|██████████| 600/600 [00:20<00:00, 29.55it/s]\n",
    "# Epoch [6], val_loss: 0.6083, val_acc: 81.1667\n",
    "# 100%|██████████| 600/600 [00:20<00:00, 29.37it/s]\n",
    "# Epoch [7], val_loss: 0.6031, val_acc: 80.3333\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 27.43it/s]\n",
    "# Epoch [8], val_loss: 0.5747, val_acc: 81.3333\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 27.53it/s]\n",
    "# Epoch [9], val_loss: 0.5491, val_acc: 83.1667\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 28.47it/s]\n",
    "# Epoch [10], val_loss: 0.5424, val_acc: 83.1667\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 28.44it/s]\n",
    "# Epoch [11], val_loss: 0.5516, val_acc: 83.3333\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 26.27it/s]\n",
    "# Epoch [12], val_loss: 0.5268, val_acc: 82.0000\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 26.40it/s]\n",
    "# Epoch [13], val_loss: 0.5035, val_acc: 83.5000\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 26.24it/s]\n",
    "# Epoch [14], val_loss: 0.5045, val_acc: 83.6667\n",
    "# 100%|██████████| 600/600 [00:23<00:00, 25.35it/s]\n",
    "# Epoch [15], val_loss: 0.4765, val_acc: 84.3333\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 28.32it/s]\n",
    "# Epoch [16], val_loss: 0.4787, val_acc: 84.3333\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 27.69it/s]\n",
    "# Epoch [17], val_loss: 0.4639, val_acc: 84.5000\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 26.24it/s]\n",
    "# Epoch [18], val_loss: 0.4560, val_acc: 87.3333\n",
    "# 100%|██████████| 600/600 [00:25<00:00, 23.85it/s]\n",
    "# Epoch [19], val_loss: 0.4453, val_acc: 86.6667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### different initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CIFAR10Module()\n",
    "# # data = CIFAR10Data()\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False  # Freeze all layers\n",
    "# pretrained_dict = torch.load(\"state_dicts/resnet18.pt\")  # Path to saved weights\n",
    "# model.load_state_dict(pretrained_dict, strict=False) \n",
    "# model.model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) \n",
    "# # Unfreeze the last layer\n",
    "# for param in model.model.conv1.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.model.fc.parameters():\n",
    "#     param.requires_grad = True\n",
    "# model.to(device)\n",
    "# experiment = fit(epochs = 2, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)\n",
    "\n",
    "# 100%|██████████| 600/600 [00:25<00:00, 23.76it/s]\n",
    "# Epoch [0], val_loss: 1.6154, val_acc: 50.3333\n",
    "# 100%|██████████| 600/600 [00:24<00:00, 24.72it/s]\n",
    "# Epoch [1], val_loss: 1.2136, val_acc: 65.1667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without training the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the chosen parameters\n",
    "# experiment = fit(epochs = 20, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)\n",
    "\n",
    "# 100%|██████████| 600/600 [00:23<00:00, 25.89it/s]\n",
    "# Epoch [0], val_loss: 2.2501, val_acc: 19.1667\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 27.08it/s]\n",
    "# Epoch [1], val_loss: 2.1102, val_acc: 23.1667\n",
    "# 100%|██████████| 600/600 [00:24<00:00, 24.76it/s]\n",
    "# Epoch [2], val_loss: 2.0289, val_acc: 30.0000\n",
    "# 100%|██████████| 600/600 [00:23<00:00, 25.88it/s]\n",
    "# Epoch [3], val_loss: 1.9465, val_acc: 33.0000\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 28.09it/s]\n",
    "# Epoch [4], val_loss: 1.9684, val_acc: 34.6667\n",
    "# 100%|██████████| 600/600 [00:20<00:00, 28.82it/s]\n",
    "# Epoch [5], val_loss: 1.9208, val_acc: 34.8333\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 28.14it/s]\n",
    "# Epoch [6], val_loss: 1.8927, val_acc: 37.5000\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 26.74it/s]\n",
    "# Epoch [7], val_loss: 1.8597, val_acc: 36.8333\n",
    "# 100%|██████████| 600/600 [00:24<00:00, 24.80it/s]\n",
    "# Epoch [8], val_loss: 1.8191, val_acc: 39.1667\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 26.70it/s]\n",
    "# Epoch [9], val_loss: 1.8407, val_acc: 40.1667\n",
    "# 100%|██████████| 600/600 [00:22<00:00, 27.04it/s]\n",
    "# Epoch [10], val_loss: 1.8462, val_acc: 38.5000\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 27.78it/s]\n",
    "# Epoch [11], val_loss: 1.8358, val_acc: 35.5000\n",
    "# 100%|██████████| 600/600 [00:21<00:00, 27.85it/s]\n",
    "# Epoch [12], val_loss: 1.8387, val_acc: 36.3333\n",
    "# 100%|██████████| 600/600 [00:20<00:00, 29.34it/s]\n",
    "# Epoch [13], val_loss: 1.8178, val_acc: 40.0000\n",
    "# 100%|██████████| 600/600 [00:19<00:00, 31.53it/s]\n",
    "# Epoch [14], val_loss: 1.7815, val_acc: 40.3333\n",
    "# 100%|██████████| 600/600 [00:18<00:00, 31.98it/s]\n",
    "# Epoch [15], val_loss: 1.7803, val_acc: 43.6667\n",
    "# 100%|██████████| 600/600 [00:19<00:00, 31.00it/s]\n",
    "# Epoch [16], val_loss: 1.7600, val_acc: 44.0000\n",
    "# 100%|██████████| 600/600 [00:18<00:00, 33.10it/s]\n",
    "# Epoch [17], val_loss: 1.7525, val_acc: 43.3333\n",
    "# 100%|██████████| 600/600 [00:19<00:00, 31.11it/s]\n",
    "# Epoch [18], val_loss: 1.7547, val_acc: 44.5000\n",
    "# 100%|██████████| 600/600 [00:18<00:00, 32.83it/s]\n",
    "# Epoch [19], val_loss: 1.7766, val_acc: 44.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIFAR10Module(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): DressedQuantumNet(\n",
       "      (pre_net): Linear(in_features=512, out_features=85, bias=True)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "      (linear): Linear(in_features=45, out_features=128, bias=True)\n",
       "      (post_net): Linear(in_features=128, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pre_trained import *\n",
    "model = CIFAR10Module(minst=True, quantum=bs)\n",
    "model.model.fc = DressedQuantumNet(bs, bs.nb_parameters, dropout=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Unfreeze the last layer\n",
    "for param in model.model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.model.conv1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "pretrained_dict = torch.load(\"state_dicts/resnet18.pt\")  # Path to saved weights\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# Remove 'conv1' weights from pretrained_dict to avoid shape mismatch\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"conv1\" or \"fc\" not in k}\n",
    "\n",
    "# Update the current model dictionary\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "# Load the modified weights\n",
    "model.load_state_dict(model_dict, strict=False) \n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [04:56<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 2.3021, val_acc: 12.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [04:49<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], val_loss: 2.3021, val_acc: 12.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [04:42<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], val_loss: 2.3023, val_acc: 12.3333\n"
     ]
    }
   ],
   "source": [
    "# train the model with the chosen parameters\n",
    "experiment = fit(epochs = 3, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR10Module(minst=True, quantum=bs)\n",
    "model.model.fc = DressedQuantumNet(bs, bs.nb_parameters, dropout=True, pos=False)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Unfreeze the last layer\n",
    "for param in model.model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.model.conv1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "pretrained_dict = torch.load(\"state_dicts/resnet18.pt\")  # Path to saved weights\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# Remove 'conv1' weights from pretrained_dict to avoid shape mismatch\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"conv1\" or \"fc\" not in k}\n",
    "\n",
    "# Update the current model dictionary\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "# Load the modified weights\n",
    "model.load_state_dict(model_dict, strict=False) \n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the chosen parameters\n",
    "experiment = fit(epochs = 20, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Model with last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR10Module(minst=True, quantum=bs)\n",
    "model.fc = DressedQuantumNet(bs, bs.nb_parameters, dropout=False, pos=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Unfreeze the last layer\n",
    "for param in model.model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.model.conv1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "pretrained_dict = torch.load(\"state_dicts/resnet18.pt\")  # Path to saved weights\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# Remove 'conv1' weights from pretrained_dict to avoid shape mismatch\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"conv1\" or \"fc\" not in k}\n",
    "\n",
    "# Update the current model dictionary\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "# Load the modified weights\n",
    "model.load_state_dict(model_dict, strict=False) \n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the chosen parameters\n",
    "experiment = fit(epochs = 20, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Model with both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR10Module(minst=True, quantum=bs)\n",
    "model.model.fc = DressedQuantumNet(bs, bs.nb_parameters, dropout=True, pos=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Unfreeze the last layer\n",
    "for param in model.model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.model.conv1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "pretrained_dict = torch.load(\"state_dicts/resnet18.pt\")  # Path to saved weights\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# Remove 'conv1' weights from pretrained_dict to avoid shape mismatch\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"conv1\" or \"fc\" not in k}\n",
    "\n",
    "# Update the current model dictionary\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "# Load the modified weights\n",
    "model.load_state_dict(model_dict, strict=False) \n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the chosen parameters\n",
    "experiment = fit(epochs = 20, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end session if needed\n",
    "if session is not None:\n",
    "    session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
