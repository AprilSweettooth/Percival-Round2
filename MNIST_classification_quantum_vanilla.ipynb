{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying MNIST with a simple model and quantum embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by:  https://www.kaggle.com/code/geekysaint/solving-mnist-using-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the Boson Sampler\n",
    "import perceval as pcvl\n",
    "#import perceval.providers.scaleway as scw  # Uncomment to allow running on scaleway\n",
    "\n",
    "# for the machine learning model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from boson_sampler import BosonSampler\n",
    "from utils import MNIST_partial, accuracy, plot_training_metrics\n",
    "from model128 import *\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the Boson Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boson sampler defined with number of parameters = 540, and embedding size = 276\n",
      "DEVICE = cpu\n"
     ]
    }
   ],
   "source": [
    "session = None\n",
    "# to run a remote session on Scaleway, uncomment the following and fill project_id and token\n",
    "# session = scw.Session(\n",
    "#                    platform=\"sim:sampling:p100\",  # or sim:sampling:h100\n",
    "#                    project_id=\"\"  # Your project id,\n",
    "#                    token=\"\"  # Your personal API key\n",
    "#                    )\n",
    "\n",
    "# start session\n",
    "if session is not None:\n",
    "    session.start()\n",
    "# definition of the BosonSampler\n",
    "# here, we use 30 photons and 2 modes\n",
    "\n",
    "bs = BosonSampler(24,2, postselect = 2, session = session)\n",
    "print(f\"Boson sampler defined with number of parameters = {bs.nb_parameters}, and embedding size = {bs.embedding_size}\")\n",
    "\n",
    "#to display it\n",
    "# pcvl.pdisplay(bs.create_circuit())\n",
    "# define device to run the model\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset : a subset of MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset from csv file, to use for the challenge\n",
    "train_dataset = MNIST_partial(split = 'train')\n",
    "val_dataset = MNIST_partial(split='val')\n",
    "\n",
    "# definition of the dataloader, to process the data in the model\n",
    "# here, we need a batch size of 1 to use the boson sampler\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([10, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, batch, emb = None):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    images.requires_grad = True  # Only needed for special cases\n",
    "    # if self.embedding_size:\n",
    "    #     out = self(images, emb.to(self.device)) ## Generate predictions\n",
    "    # else:\n",
    "    # images = images.reshape(-1,1,28,28)\n",
    "    # print(images.shape)\n",
    "\n",
    "    # out = model(images) ## Generate predictions\n",
    "    # loss = F.cross_entropy(out, labels)\n",
    "    # acc = accuracy(out, labels, task=\"multiclass\", num_classes=10)\n",
    "    loss, acc = model((images, labels)) ## Generate predictions\n",
    "    \n",
    "    # loss = F.cross_entropy(out, labels) ## Calculate the loss\n",
    "    # acc = accuracy(out, labels)\n",
    "    return loss, acc\n",
    "\n",
    "def validation_step(model, batch, emb =None):\n",
    "    images, labels = batch\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    images.requires_grad = True  # Only needed for special cases\n",
    "    # if self.embedding_size:\n",
    "    #     out = self(images, emb.to(self.device)) ## Generate predictions\n",
    "    # # else:\n",
    "    # out = model(images) ## Generate predictions\n",
    "    # loss = F.cross_entropy(out, labels)\n",
    "    # acc = accuracy(out, labels, task=\"multiclass\", num_classes=10)\n",
    "    loss, acc = model((images,labels)) ## Generate predictions\n",
    "    return({'val_loss':loss, 'val_acc': acc})\n",
    "\n",
    "def validation_epoch_end(outputs):\n",
    "    batch_losses = [x['val_loss'] for x in outputs]\n",
    "    epoch_loss = torch.stack(batch_losses).mean()\n",
    "    batch_accs = [x['val_acc'] for x in outputs]\n",
    "    epoch_acc = torch.stack(batch_accs).mean()\n",
    "    return({'val_loss': epoch_loss.item(), 'val_acc' : epoch_acc.item()})\n",
    "\n",
    "def epoch_end(epoch, result):\n",
    "    print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "    return result['val_loss'], result['val_acc']\n",
    "\n",
    "# training loop\n",
    "def fit(epochs, lr, model, train_loader, val_loader, bs: BosonSampler, opt_func = torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func([{'params': model.model.fc.parameters(), 'lr': lr},{'params': model.model.conv1.parameters(), 'lr': lr}])\n",
    "    # creation of empty lists to store the training metrics\n",
    "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "    for epoch in range(epochs):\n",
    "        training_losses, training_accs = 0, 0\n",
    "        ## Training Phase\n",
    "        for step, batch in enumerate(tqdm(train_loader)):\n",
    "            # # embedding in the BS\n",
    "            # if model.embedding_size:\n",
    "            #     images, labs = batch\n",
    "            #     images = images.squeeze(0).squeeze(0)\n",
    "            #     t_s = time.time()\n",
    "            #     embs = bs.embed(images,1000)\n",
    "            #     loss,acc = model.training_step(batch,emb = embs.unsqueeze(0))\n",
    "\n",
    "            # else:\n",
    "            \n",
    "            loss,acc = training_step(model, batch)\n",
    "            # loss.requires_grad = True\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backpropagation with boson sampling noise\n",
    "            # for param in model.parameters():\n",
    "            #     param.grad = param.grad + bs(param.grad.shape, scale=0.001)\n",
    "\n",
    "            training_losses+=int(loss.detach())\n",
    "            training_accs+=int(acc.detach())\n",
    "            # if model.embedding_size and step%100==0:\n",
    "            #     print(f\"STEP {step}, Training-acc = {training_accs/(step+1)}, Training-losses = {training_losses/(step+1)}\")\n",
    "        \n",
    "        ## Validation phase\n",
    "        outputs = [validation_step(model, batch) for batch in val_loader]\n",
    "        result = (validation_epoch_end(outputs))\n",
    "        # result = evaluate(model, val_loader, bs)\n",
    "        validation_loss, validation_acc = result['val_loss'], result['val_acc']\n",
    "        epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "\n",
    "        ## summing up all the training and validation metrics\n",
    "        training_loss = training_losses/len(train_loader)\n",
    "        training_accs = training_accs/len(train_loader)\n",
    "        train_loss.append(training_loss)\n",
    "        train_acc.append(training_accs)\n",
    "        val_loss.append(validation_loss)\n",
    "        val_acc.append(validation_acc)\n",
    "\n",
    "        # plot training curves\n",
    "        \n",
    "\n",
    "    with open('tmp_file.txt', 'w') as f:\n",
    "        csv.writer(f, delimiter=' ').writerows([train_acc,val_acc,train_loss,val_loss])\n",
    "        # plot_training_metrics(train_acc,val_acc,train_loss,val_loss)\n",
    "    return(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_trained import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MnistModel()\n",
    "# pretrained_dict = torch.load(\"cifar_net.pth\")  # Path to saved weights\n",
    "# model.load_state_dict(pretrained_dict, strict=False) \n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) \n",
    "# # Unfreeze the last layer\n",
    "# for param in model.conv1.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.fc2.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# model = CIFAR10Module(minst=True,vanilla=True)\n",
    "# # data = CIFAR10Data()\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# # Unfreeze the last layer\n",
    "# for param in model.model.conv1.parameters():\n",
    "#     param.requires_grad = True\n",
    "# for param in model.model.fc.parameters():\n",
    "#     param.requires_grad = True\n",
    "# pretrained_dict = torch.load(\"cifar_vanilla.pth\")  # Path to saved weights\n",
    "# model_dict = model.state_dict()\n",
    "\n",
    "# # Remove 'conv1' weights from pretrained_dict to avoid shape mismatch\n",
    "# pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"conv1\" or 'fc' not in k}\n",
    "\n",
    "# # Update the current model dictionary\n",
    "# model_dict.update(pretrained_dict)\n",
    "\n",
    "# # Load the modified weights\n",
    "# model.load_state_dict(model_dict, strict=False) \n",
    "# model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = fit(epochs = 20, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIFAR10Module(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (model): MnistModel(\n",
       "    (conv1): Conv2d(1, 6, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (linear): Linear(in_features=294, out_features=512, bias=True)\n",
       "    (fc): DressedQuantumNet(\n",
       "      (pre_net): Linear(in_features=512, out_features=540, bias=True)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "      (linear): Linear(in_features=276, out_features=128, bias=True)\n",
       "      (post_net): Linear(in_features=128, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CIFAR10Module(minst=True, vanilla=True)\n",
    "model.model.fc = DressedQuantumNet(bs, bs.nb_parameters, dropout=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "# Unfreeze the last layer\n",
    "for param in model.model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.model.conv1.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "pretrained_dict = torch.load(\"cifar_vanilla.pth\")  # Path to saved weights\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# Remove 'conv1' weights from pretrained_dict to avoid shape mismatch\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if \"conv1\" or \"fc\" not in k}\n",
    "\n",
    "# Update the current model dictionary\n",
    "model_dict.update(pretrained_dict)\n",
    "\n",
    "# Load the modified weights\n",
    "model.load_state_dict(model_dict, strict=False) \n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [37:46<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 2.3063, val_acc: 9.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [33:20<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], val_loss: 2.3057, val_acc: 9.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [33:13<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], val_loss: 2.3052, val_acc: 9.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [33:06<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], val_loss: 2.3048, val_acc: 9.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 303/600 [1:03:26<1:02:10, 12.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train the model with the chosen parameters\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m experiment \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 64\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, bs, opt_func)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m## Training Phase\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# # embedding in the BS\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# if model.embedding_size:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     loss,acc \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# loss.requires_grad = True\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m, in \u001b[0;36mtraining_step\u001b[0;34m(model, batch, emb)\u001b[0m\n\u001b[1;32m      4\u001b[0m images\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Only needed for special cases\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# if self.embedding_size:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     out = self(images, emb.to(self.device)) ## Generate predictions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# loss = F.cross_entropy(out, labels)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# acc = accuracy(out, labels, task=\"multiclass\", num_classes=10)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m## Generate predictions\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# loss = F.cross_entropy(out, labels) ## Calculate the loss\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# acc = accuracy(out, labels)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, acc\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Percival-Round-2/pre_trained.py:175\u001b[0m, in \u001b[0;36mCIFAR10Module.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    174\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 175\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(predictions, labels)\n\u001b[1;32m    177\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccuracy(predictions, labels, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Percival-Round-2/vanilla.py:24\u001b[0m, in \u001b[0;36mMnistModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# flatten all dimensions except batch\u001b[39;00m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n\u001b[0;32m---> 24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Percival-Round-2/model128.py:49\u001b[0m, in \u001b[0;36mDressedQuantumNet.forward\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m     46\u001b[0m q_out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m pre_out:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# print(elem.shape)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout:\n\u001b[1;32m     51\u001b[0m         embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(embs)\n",
      "File \u001b[0;32m~/Downloads/Percival-Round-2/boson_sampler.py:72\u001b[0m, in \u001b[0;36mBosonSampler.embed\u001b[0;34m(self, t, n_sample)\u001b[0m\n\u001b[1;32m     68\u001b[0m     t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((t, z), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     70\u001b[0m t \u001b[38;5;241m=\u001b[39m t \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mpi  \u001b[38;5;66;03m# Phases are 2 pi periodic --> we get better expressivity by multiplying the values by 2 pi\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_sample\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This is a dict with states as keys and probabilities as values\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslate_results(res)\n",
      "File \u001b[0;32m~/Downloads/Percival-Round-2/boson_sampler.py:139\u001b[0m, in \u001b[0;36mBosonSampler.run\u001b[0;34m(self, parameters, samples)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_processor(proc, parameters)\n\u001b[1;32m    138\u001b[0m sampler \u001b[38;5;241m=\u001b[39m pcvl\u001b[38;5;241m.\u001b[39malgorithm\u001b[38;5;241m.\u001b[39mSampler(proc, max_shots_per_call\u001b[38;5;241m=\u001b[39msamples)\n\u001b[0;32m--> 139\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/perceval/runtime/job.py:80\u001b[0m, in \u001b[0;36mJob.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/perceval/runtime/local_job.py:86\u001b[0m, in \u001b[0;36mLocalJob.execute_sync\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_delta_parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprogress_callback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress_cb\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_params(args, kwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_fn_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delta_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcommand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_results()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/perceval/runtime/local_job.py:96\u001b[0m, in \u001b[0;36mLocalJob._call_fn_safe\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# it has already been called, calling it again to get more precise running time\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_status\u001b[38;5;241m.\u001b[39mstart_run()\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cancel_requested:\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_status\u001b[38;5;241m.\u001b[39mstop_run(RunningStatus\u001b[38;5;241m.\u001b[39mCANCELED, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser has canceled the job\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/perceval/algorithm/sampler.py:185\u001b[0m, in \u001b[0;36mSampler._probs_wrapper\u001b[0;34m(self, progress_callback)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_probs_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, progress_callback: Callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# max_shots is used as the invert of the precision set in the probs computation\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Rationale: mimic the fact that the more shots, the more accurate probability distributions are.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_shots \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_shots)\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/perceval/components/processor.py:272\u001b[0m, in \u001b[0;36mProcessor.probs\u001b[0;34m(self, precision, progress_callback)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mperceval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimulatorFactory  \u001b[38;5;66;03m# Avoids a circular import\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulator \u001b[38;5;241m=\u001b[39m \u001b[43mSimulatorFactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulator\u001b[38;5;241m.\u001b[39mset_circuit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_circuit() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_unitary \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/perceval/simulators/simulator_factory.py:82\u001b[0m, in \u001b[0;36mSimulatorFactory.build\u001b[0;34m(circuit, backend, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m heralds \u001b[38;5;241m=\u001b[39m circuit\u001b[38;5;241m.\u001b[39mheralds\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m circuit\u001b[38;5;241m.\u001b[39m_is_unitary:\n\u001b[0;32m---> 82\u001b[0m     circuit \u001b[38;5;241m=\u001b[39m \u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     circuit \u001b[38;5;241m=\u001b[39m circuit\u001b[38;5;241m.\u001b[39mcomponents\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/perceval/components/processor.py:246\u001b[0m, in \u001b[0;36mProcessor.linear_circuit\u001b[0;34m(self, flatten)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlinear_circuit\u001b[39m(\u001b[38;5;28mself\u001b[39m, flatten: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Circuit:\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    Creates a linear circuit from internal components, if all internal components are unitary. Takes phase\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    imprecision noise into account.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    :return: The resulting Circuit object\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_phase_quantization:\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m circuit\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/perceval/components/abstract_processor.py:389\u001b[0m, in \u001b[0;36mAProcessor.linear_circuit\u001b[0;34m(self, flatten)\u001b[0m\n\u001b[1;32m    387\u001b[0m circuit \u001b[38;5;241m=\u001b[39m Circuit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcircuit_size)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos_m, component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_components:\n\u001b[0;32m--> 389\u001b[0m     \u001b[43mcircuit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m circuit\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/perceval/components/linear_circuit.py:488\u001b[0m, in \u001b[0;36mCircuit.add\u001b[0;34m(self, port_range, component, merge, x_grid)\u001b[0m\n\u001b[1;32m    486\u001b[0m     port_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(port_range)\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(port_range, \u001b[38;5;28mtuple\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport_range\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be a tuple\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 488\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mport_range\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m x \u001b[38;5;241m==\u001b[39m port_range[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \\\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange must be a consecutive set of port indexes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(port_range) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(port_range) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm, \\\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPort range exceeds circuit size (received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport_range\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but maximum expected value is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model with the chosen parameters\n",
    "experiment = fit(epochs = 20, lr = 0.001, model = model, train_loader = train_loader, val_loader = val_loader, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end session if needed\n",
    "if session is not None:\n",
    "    session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
